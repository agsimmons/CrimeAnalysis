{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Traffic Stop Analysis\n",
    "By. Andrew Simmons & Ethan Smith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load data and filter\"\"\"\n",
    "\n",
    "dataset = pd.read_csv('data/boston-police-department-fio.csv')\n",
    "\n",
    "dataset.replace('NO DATA ENTERED', np.NaN, inplace=True)\n",
    "dataset.replace('UNKNOWN', np.NaN, inplace=True)\n",
    "\n",
    "dataset['VEH_YEAR_NUM'] = dataset['VEH_YEAR_NUM'].replace(0, np.NaN)\n",
    "dataset['AGE_AT_FIO_CORRECTED'] = dataset['AGE_AT_FIO_CORRECTED'].replace(0, np.NaN)\n",
    "dataset['AGE_AT_FIO_CORRECTED'] = dataset['AGE_AT_FIO_CORRECTED'].replace(-1, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sort(dataset['AGE_AT_FIO_CORRECTED'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sex Distibution\"\"\"\n",
    "\n",
    "males = len(dataset[dataset['SEX'] == 'MALE'].index)\n",
    "females = len(dataset[dataset['SEX'] == 'FEMALE'].index)\n",
    "\n",
    "sexes = ['Male', 'Female']\n",
    "counts = np.array([males, females])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((10, 10))\n",
    "\n",
    "sex_distribution = ax.pie(counts,\n",
    "                           explode=[0, 0.15],\n",
    "                           shadow=True,\n",
    "                           labels=sexes,\n",
    "                           autopct=\"%1.1f%%\")\n",
    "\n",
    "ax.set_title('Sex Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prior Offenses\"\"\"\n",
    "\n",
    "has_prior_offenses = len(dataset[dataset['PRIORS'] == 'YES'].index)\n",
    "no_prior_offenses = len(dataset[dataset['PRIORS'] == 'NO'].index)\n",
    "\n",
    "labels = ['Yes', 'No']\n",
    "counts = [has_prior_offenses, no_prior_offenses]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((10, 10))\n",
    "\n",
    "sex_distribution = ax.pie(counts,\n",
    "                           explode=[0, 0.15],\n",
    "                           shadow=True,\n",
    "                           labels=labels,\n",
    "                           autopct=\"%1.1f%%\")\n",
    "\n",
    "ax.set_title('Prior Offenses Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Terrorism Distribution\"\"\"\n",
    "\n",
    "terrorism = len(dataset[dataset['TERRORISM'] == 'YES'].index)\n",
    "no_terrorism = len(dataset[dataset['TERRORISM'] == 'NO'].index)\n",
    "\n",
    "labels = ['Terrorism', 'Non-Terrorism']\n",
    "counts = [terrorism, no_terrorism]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((10, 10))\n",
    "\n",
    "sex_distribution = ax.pie(counts,\n",
    "                           shadow=True,\n",
    "                           labels=labels,\n",
    "                           autopct=\"%1.1f%%\")\n",
    "\n",
    "ax.set_title('Terrorism Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Vehicle Make Distribution\"\"\"\n",
    "\n",
    "without_null_vehicle_makes = dataset[~pd.isnull(dataset['VEH_MAKE'])]\n",
    "vehicle_makes = list(without_null_vehicle_makes['VEH_MAKE'].unique())\n",
    "\n",
    "counts = []\n",
    "for make in vehicle_makes:\n",
    "    counts.append(len(without_null_vehicle_makes[without_null_vehicle_makes['VEH_MAKE'] == make].index))\n",
    "    \n",
    "make_counts = sorted(zip(vehicle_makes, counts), key=itemgetter(1), reverse=True)\n",
    "makes, counts = zip(*make_counts)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((10, 10))\n",
    "\n",
    "sex_distribution = ax.bar(makes, counts)\n",
    "\n",
    "ax.set_title('Vehicle Make Distribution')\n",
    "\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Race Distribution\"\"\"\n",
    "\n",
    "without_null_race = dataset[~pd.isnull(dataset['RACE_DESC'])]\n",
    "races = list(without_null_race['RACE_DESC'].unique())\n",
    "\n",
    "counts = []\n",
    "for race in races:\n",
    "    counts.append(len(without_null_race[without_null_race['RACE_DESC'] == race].index))\n",
    "\n",
    "race_counts = sorted(zip(races, counts), key=itemgetter(1), reverse=True)\n",
    "races, counts = zip(*race_counts)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((10, 10))\n",
    "\n",
    "sex_distribution = ax.bar(races, counts)\n",
    "\n",
    "ax.set_title('Race Distribution')\n",
    "\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Race Distribution Without Priors\"\"\"\n",
    "\n",
    "without_null_race = dataset[~pd.isnull(dataset['RACE_DESC'])]\n",
    "without_priors = without_null_race[without_null_race['PRIORS'] == 'NO']\n",
    "races = list(without_priors['RACE_DESC'].unique())\n",
    "\n",
    "counts = []\n",
    "for race in races:\n",
    "    counts.append(len(without_priors[without_priors['RACE_DESC'] == race].index))\n",
    "\n",
    "race_counts = sorted(zip(races, counts), key=itemgetter(1), reverse=True)\n",
    "races, counts = zip(*race_counts)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((10, 10))\n",
    "\n",
    "sex_distribution = ax.bar(races, counts)\n",
    "\n",
    "ax.set_title('Race Distribution Without Priors')\n",
    "\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['setosa', 'versicolor', 'verginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Decision Tree\"\"\"\n",
    "\n",
    "LABEL_FEATURES = 'PRIORS'\n",
    "NAN_REPLACEMENT_VALUE = '__REPLACE_ME_WITH_NAN__'\n",
    "\n",
    "# Select columns to include in model\n",
    "important_features = dataset[\n",
    "    [\n",
    "        'SEX',\n",
    "        'PRIORS',\n",
    "        'COMPLEXION',\n",
    "        'TERRORISM',\n",
    "        'BASIS',\n",
    "        'STOP_REASONS',\n",
    "        'FIOFS_REASONS',\n",
    "        'VEH_MAKE',\n",
    "        'VEH_YEAR_NUM',\n",
    "        'VEH_COLOR',\n",
    "        'VEH_OCCUPANT',\n",
    "        'VEH_STATE',\n",
    "        'RACE_DESC',\n",
    "        'AGE_AT_FIO_CORRECTED',\n",
    "        'CITY',\n",
    "    ]\n",
    "]\n",
    "# TODO: Conside the following features:\n",
    "#     FIOFS_TYPE: Figure out what these mean\n",
    "#     SEARCH: Figure out what these mean\n",
    "#     OUTCOME: Figure out what these mean\n",
    "\n",
    "\n",
    "# TODO: Remove Debug\n",
    "important_features.to_csv('data/cleaned_decision_tree_features.csv', index=False)\n",
    "\n",
    "label_mappings = {}\n",
    "for column_name in important_features.columns:\n",
    "    column = important_features[column_name]\n",
    "    column_dtype = column.dtype\n",
    "    \n",
    "    # Skip column if it's dtype is not object\n",
    "    if column_dtype != np.dtype(np.object):\n",
    "        continue\n",
    "    \n",
    "    # Step 1 - Replace NaN with a string\n",
    "    column.replace(np.NaN, NAN_REPLACEMENT_VALUE, inplace=True)\n",
    "    \n",
    "    column_possible_values = column.unique()\n",
    "    \n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(column_possible_values)\n",
    "    \n",
    "    has_nans = False\n",
    "    if NAN_REPLACEMENT_VALUE in column:\n",
    "        has_nans = True\n",
    "    \n",
    "    if has_nans:\n",
    "        # Determine the encoded value of NAN_REPLACEMENT_VALUE\n",
    "        nan_encoded_value = label_encoder.transform([NAN_REPLACEMENT_VALUE])[0]\n",
    "    \n",
    "    column = label_encoder.fit_transform(column)\n",
    "    \n",
    "    # Step 2 - Replace NaN string with NaN\n",
    "#     if has_nans:\n",
    "#         column.replace(nan_encoded_value, np.NaN, inplace=True)\n",
    "    \n",
    "    important_features[column_name] = column\n",
    "    \n",
    "    label_mappings[column_name] = label_encoder\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(important_features.drop(LABEL_FEATURES, axis=1),\n",
    "                                                    important_features[LABEL_FEATURES],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
